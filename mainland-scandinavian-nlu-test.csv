model_id,num_model_parameters,vocabulary_size,max_sequence_length,speed,rank,da_rank,no_rank,sv_rank,dansk,angry_tweets,scala_da,scandiqa_da,norne_nb,norne_nn,norec,scala_nb,scala_nn,norquad,suc3,swerec,scala_sv,scandiqa_sv
"gpt-4-0613 (few-shot, val)",-1,100,8192,1244,1.29,1.29,1.45,1.12,64.94,59.97,71.56,49.82,81.16,75.75,72.72,77.3,57.18,49.93,76.86,79.19,80.93,56.5
AI-Sweden-Models/roberta-large-1160k,355,50,512,5741,1.3,1.33,1.34,1.23,74.16,51.2,73.87,49.34,92.01,87.17,60.11,72.85,65.56,60.38,82.65,77.25,77.9,49.64
ltg/norbert3-large,354,50,508,5048,1.31,1.42,1.13,1.39,73.62,48.29,71.55,48.59,93.12,89.39,64.62,77.97,76.3,66.03,79.01,75.32,69.11,48.88
AI-Sweden-Models/roberta-large-1350k,355,50,512,5744,1.33,1.37,1.36,1.25,75.22,49.94,72.59,48.97,92.49,87.22,58.77,76.3,64.11,60.69,82.97,77.37,73.81,49.5
danish-foundation-models/encoder-large-v1,355,50,512,6671,1.45,1.3,1.55,1.51,74.6,51.42,76.11,47.42,88.66,84.59,55.59,71.43,53.3,57.38,74.18,75.11,64.11,46.79
KennethEnevoldsen/dfm-sentence-encoder-large-1,355,50,512,6245,1.46,1.31,1.5,1.57,74.99,53.85,75.71,44.85,86.39,83.22,59.61,67.88,62.44,55.69,71.65,74.92,63.43,46.2
KennethEnevoldsen/dfm-sentence-encoder-large-2,355,50,512,6569,1.49,1.31,1.54,1.61,75.3,55.12,76.34,45.15,86.78,83.28,58.73,70.73,59.58,56.04,71.86,74.67,62.77,44.77
google/rembert,576,250,256,3355,1.51,1.54,1.58,1.4,70.19,50.19,69.72,39.85,88.7,86.11,54.19,69.83,54.84,58.18,78.23,75.99,72.17,46.0
intfloat/multilingual-e5-large,560,250,512,6732,1.54,1.55,1.68,1.39,69.5,55.07,57.67,46.71,89.86,84.32,61.52,62.34,34.88,53.01,80.36,79.65,63.15,46.99
NbAiLab/nb-roberta-base-scandi,278,250,512,15079,1.58,1.64,1.55,1.55,73.28,52.08,67.99,32.39,92.24,87.58,59.98,70.18,70.81,44.27,80.02,76.21,71.92,33.8
microsoft/mdeberta-v3-base,279,251,512,9237,1.58,1.68,1.65,1.41,72.9,43.38,67.05,42.15,91.9,86.81,53.69,70.55,61.21,48.82,78.84,75.24,72.3,44.74
NbAiLab/nb-roberta-base-scandi-1e4,278,250,512,15074,1.61,1.74,1.52,1.58,72.16,51.7,62.03,29.95,92.09,86.85,59.84,73.33,71.06,43.67,79.9,76.2,73.62,32.38
ltg/norbert3-base,124,50,508,11405,1.61,1.82,1.34,1.66,73.26,43.94,51.62,40.7,92.36,88.49,59.73,74.4,68.85,57.67,78.21,71.05,56.02,42.52
sentence-transformers/use-cmlm-multilingual,471,501,512,13305,1.63,1.76,1.67,1.47,69.17,48.03,55.31,42.34,90.08,86.04,56.35,59.38,46.54,55.05,80.05,75.09,61.83,45.69
FacebookAI/xlm-roberta-large,560,250,512,6663,1.64,1.64,1.74,1.53,72.74,48.33,57.3,43.57,91.66,86.19,50.25,55.51,43.89,57.57,80.33,76.63,49.72,46.64
KennethEnevoldsen/dfm-sentence-encoder-medium-3,178,120,512,14050,1.65,1.65,1.68,1.63,71.21,47.55,68.72,38.33,91.17,87.3,59.1,74.32,72.94,34.06,81.35,71.16,63.89,37.18
vesteinn/ScandiBERT-no-faroese,124,50,512,15436,1.66,1.77,1.66,1.56,69.79,47.73,68.28,31.9,91.09,85.72,50.9,69.34,66.24,48.45,79.08,72.53,73.01,36.92
NbAiLab/nb-bert-base,178,120,512,14050,1.68,1.74,1.63,1.67,70.36,46.32,66.41,36.42,93.01,88.43,60.84,73.89,72.1,33.01,80.38,71.21,64.03,35.33
gpt-3.5-turbo-0613 (few-shot),-1,100,4096,1344,1.7,1.59,2.05,1.46,59.4,51.8,54.22,56.55,74.92,75.34,57.64,49.93,34.22,44.39,71.43,77.5,55.99,55.46
"gpt-3.5-turbo-0613 (few-shot, val)",-1,100,4095,1344,1.71,1.66,1.99,1.47,59.61,50.54,57.57,51.09,77.7,73.92,58.88,54.29,32.82,46.44,73.04,72.77,58.06,57.59
vesteinn/FoBERT,124,50,512,15623,1.71,1.77,1.72,1.65,69.65,49.18,65.45,32.4,90.65,84.88,52.44,68.77,65.4,43.13,78.58,73.41,71.14,31.62
pere/roberta-debug-8,278,250,512,15103,1.72,1.77,1.71,1.69,71.34,49.77,64.31,31.86,91.16,84.75,55.25,68.03,66.9,41.65,74.48,74.58,69.07,31.66
pere/roberta-base-exp-8,278,250,512,15112,1.73,1.81,1.62,1.77,68.77,49.66,60.13,32.6,88.99,82.99,57.37,69.92,70.05,41.98,73.44,73.63,58.91,32.39
setu4993/LaBSE,471,501,512,13386,1.74,1.77,1.84,1.6,71.24,46.5,52.92,40.08,90.58,85.21,54.26,59.44,49.3,46.42,77.78,73.58,60.36,41.71
pere/roberta-debug-32,278,250,512,14958,1.78,1.79,1.84,1.7,68.46,50.48,64.34,30.3,89.07,83.27,53.23,70.06,66.81,34.17,72.25,75.04,70.16,31.89
pere/roberta-base-exp-32,278,250,512,15081,1.79,1.93,1.67,1.76,71.9,51.33,44.45,32.51,91.66,87.74,57.43,63.31,62.79,41.05,79.75,74.73,53.55,32.2
AI-Sweden-Models/bert-large-nordic-pile-1M-steps,369,64,512,6571,1.9,2.08,2.22,1.39,67.4,41.53,41.62,37.3,87.5,80.57,47.11,52.62,25.06,38.4,80.65,77.43,76.56,41.54
pere/roberta-base-exp-32B,278,250,512,15103,1.96,1.91,2.05,1.91,71.81,47.83,54.99,29.92,90.6,86.76,52.19,54.98,58.33,29.17,77.97,73.27,47.19,31.07
vesteinn/DanskBERT,124,50,512,15749,1.96,1.49,2.22,2.17,72.55,52.86,75.2,37.65,86.82,79.91,47.84,51.99,30.57,36.75,72.33,67.77,33.79,32.71
ltg/norbert3-small,41,50,508,13515,2.01,2.12,1.74,2.18,67.89,39.34,50.9,34.82,90.02,86.52,51.36,67.29,56.67,48.63,74.22,63.8,37.77,31.45
KBLab/megatron-bert-large-swedish-cased-165k,370,64,512,7138,2.04,2.32,2.49,1.3,58.5,41.02,27.1,39.99,85.99,79.47,39.53,27.39,23.56,39.01,81.05,78.0,76.79,45.71
AI-Nordics/bert-large-swedish-cased,335,31,512,7199,2.09,2.35,2.52,1.41,60.66,38.46,32.29,37.68,83.32,77.97,38.44,37.54,23.1,39.97,78.61,77.47,72.87,43.11
"RJuro/munin-neuralbeagle-7b (few-shot, val)",7242,32,32768,2493,2.09,1.95,2.46,1.85,51.44,54.91,22.77,56.7,61.18,65.16,55.61,20.84,9.12,42.98,62.96,77.13,15.73,58.43
cardiffnlp/twitter-xlm-roberta-base,278,250,512,14837,2.1,2.11,2.31,1.88,70.1,45.3,51.74,22.01,87.7,81.41,48.34,55.3,37.46,24.49,72.49,70.69,56.6,31.89
KBLab/megatron-bert-large-swedish-cased-110k,370,64,512,7075,2.11,2.39,2.62,1.32,60.18,39.2,26.68,39.34,84.03,77.98,39.15,21.39,17.1,35.32,80.39,78.45,76.28,44.56
"timpal0l/BeagleCatMunin (few-shot, val)",7242,32,32768,2495,2.15,2.01,2.58,1.86,47.62,54.73,21.8,57.39,54.04,62.21,54.74,14.51,5.38,42.71,50.53,77.37,27.84,59.92
"birgermoell/Flashback-Bellman (few-shot, val)",7242,32,32768,2887,2.17,2.07,2.61,1.84,47.71,48.21,19.55,58.27,56.44,66.56,53.24,11.96,2.5,42.02,55.29,78.29,18.45,60.18
"merge-crew/da-sv-dare-ties-density-0.9 (few-shot, val)",7242,32,32768,2443,2.17,2.07,2.55,1.89,45.61,53.73,17.08,56.67,48.24,61.5,49.4,24.12,13.2,47.93,46.61,76.38,34.16,58.77
"merge-crew/da-sv-slerp (few-shot, val)",7242,32,32768,2467,2.17,1.97,2.67,1.86,45.94,51.75,28.04,57.65,49.67,61.11,56.07,3.81,-1.29,44.98,46.57,76.53,33.43,59.87
"merge-crew/da-sv-task-arithmetic (few-shot, val)",7242,32,32768,2500,2.17,1.97,2.68,1.86,46.06,51.51,27.68,57.78,49.69,61.78,55.87,2.99,-1.29,44.62,47.28,76.62,33.23,60.0
mhenrichsen/danskgpt-chat-v2.1 (few-shot),-1,32,32768,5085,2.18,1.9,2.64,2.01,51.08,54.69,30.95,56.56,62.43,60.68,53.41,-1.16,0.3,49.15,54.37,75.98,17.98,55.07
microsoft/infoxlm-large,560,250,512,6696,2.19,2.25,2.48,1.84,74.42,37.94,15.26,44.25,91.9,86.59,30.56,9.79,6.36,60.47,79.53,75.42,18.44,48.19
google-bert/bert-base-multilingual-uncased,167,106,512,13993,2.2,2.27,2.32,2.02,64.92,33.5,46.75,37.09,82.9,77.33,37.28,49.41,43.58,40.35,70.85,63.3,48.97,38.0
Mabeck/Heidrun-Mistral-7B-chat (few-shot),7242,32,32768,5822,2.21,2.15,2.54,1.94,50.8,42.79,23.25,59.82,61.41,59.49,49.19,15.17,10.78,48.98,55.06,77.5,17.47,58.6
"birgermoell/BeagleCatMunin-Flashback-Bellman (few-shot, val)",7242,32,32768,2890,2.21,2.01,2.65,1.97,50.4,52.3,21.3,58.23,53.96,63.45,52.7,14.87,2.48,41.56,52.96,76.99,14.27,60.1
KB/bert-base-swedish-cased,125,50,512,16181,2.22,2.54,2.72,1.4,61.74,33.28,33.15,28.67,85.91,79.67,38.7,39.13,24.13,19.04,81.95,75.58,78.86,38.56
KBLab/megatron-bert-base-swedish-cased-600k,135,64,512,15726,2.22,2.51,2.66,1.49,57.97,39.4,23.5,31.87,82.2,76.64,40.2,24.45,19.18,30.69,78.91,76.09,70.08,41.14
"birgermoell/Rapid-Cycling (few-shot, val)",7242,32,32768,2346,2.22,2.06,2.71,1.89,49.99,51.25,20.66,56.81,55.93,63.85,50.41,15.74,2.23,39.87,53.66,77.72,16.22,59.81
"timpal0l/BeagleCatMunin2 (few-shot, val)",7242,32,32768,2477,2.22,2.16,2.47,2.02,51.53,47.95,14.1,58.28,61.17,65.44,58.69,15.03,5.95,42.42,60.87,73.72,6.78,58.69
Geotrend/bert-base-en-fr-de-no-da-cased,118,42,512,13973,2.23,2.2,2.42,2.06,63.38,34.78,41.08,40.32,88.05,83.08,35.34,31.45,36.12,41.59,76.55,61.6,37.44,39.32
google-bert/bert-base-multilingual-cased,178,120,512,14083,2.23,2.4,2.35,1.95,63.17,32.38,27.93,39.57,88.72,83.08,35.87,44.22,39.55,40.55,76.29,61.78,47.74,41.17
"mlabonne/NeuralBeagle14-7B (few-shot, val)",7242,32,8192,2549,2.23,2.09,2.62,1.99,53.02,51.29,19.73,51.75,62.47,66.69,54.04,16.75,13.0,34.48,61.25,76.03,16.28,50.96
Geotrend/bert-base-25lang-cased,151,85,512,13908,2.24,2.4,2.31,2.0,62.53,32.88,29.01,39.51,87.99,83.1,36.21,46.43,39.82,40.01,75.62,62.5,38.18,40.96
Geotrend/bert-base-en-no-cased,111,33,512,14081,2.24,2.26,2.4,2.06,62.66,33.91,40.96,39.93,89.07,82.69,34.97,39.58,31.27,41.89,75.33,61.8,36.62,39.95
KBLab/bert-base-swedish-cased,125,50,512,16164,2.24,2.54,2.75,1.42,61.74,33.31,33.35,28.67,85.33,79.44,38.17,39.49,22.17,19.04,81.23,75.73,78.6,38.56
"merge-crew/da-sv-ties (few-shot, val)",7242,32,32768,2457,2.26,2.12,2.66,2.01,45.39,51.95,13.25,58.51,47.61,60.57,44.46,23.99,11.6,47.02,48.36,76.57,20.94,59.07
microsoft/xlm-align-base,278,250,512,14744,2.26,2.37,2.25,2.17,70.36,47.83,11.87,29.87,90.07,85.65,54.46,12.16,8.99,49.24,78.6,73.67,15.41,32.41
"birgermoell/Munin-NeuralBeagle-NorskGPT (few-shot, val)",7242,32,32768,2903,2.27,2.37,2.39,2.04,51.85,44.02,1.22,57.38,63.33,68.84,58.28,18.65,10.72,44.57,63.85,73.72,-0.56,59.98
"birgermoell/WestLake-Munin-Cat-NorskGPT (few-shot, val)",7242,32,32768,2856,2.27,2.37,2.39,2.04,51.85,44.02,1.22,57.38,63.33,68.84,58.28,18.65,10.72,44.57,63.85,73.72,-0.56,59.98
facebook/xlm-v-base,778,902,512,13135,2.27,2.18,2.74,1.88,71.42,31.86,52.95,34.66,89.99,78.6,17.93,43.46,10.97,43.74,68.39,73.43,45.09,38.04
"merge-crew/da-sv-dare-ties-density-0.6 (few-shot, val)",7242,32,32768,2515,2.27,2.22,2.62,1.96,46.03,49.59,12.72,57.03,47.26,59.35,54.93,9.0,5.26,45.95,45.12,78.74,19.74,60.15
Geotrend/bert-base-en-da-cased,111,33,512,14062,2.29,2.35,2.47,2.06,62.57,33.67,35.79,38.77,88.55,83.09,35.16,31.82,32.94,39.46,74.88,61.89,40.22,39.95
"RJuro/munin-neuralbeagle-SkoleGPTOpenOrca-7b (few-shot, val)",7242,32,32768,3008,2.3,2.17,2.75,1.97,50.83,43.41,19.72,57.88,53.68,61.92,47.78,0.91,1.24,47.95,59.36,72.04,22.38,58.03
"timpal0l/tyr (few-shot, val)",7242,32,32768,6079,2.31,2.24,2.75,1.95,41.65,50.6,13.73,56.35,57.62,60.06,51.85,0.66,0.53,43.22,53.5,78.3,14.35,61.08
jonfd/electra-small-nordic,22,96,128,5989,2.32,2.46,2.35,2.14,65.4,34.43,67.27,6.6,84.95,79.57,40.15,72.87,63.77,14.16,71.07,66.42,69.19,11.85
Geotrend/bert-base-da-cased,104,23,512,15432,2.34,2.39,2.53,2.11,62.76,32.06,30.95,37.79,87.52,82.66,32.73,36.41,30.37,37.71,74.13,62.18,36.93,37.59
Mabeck/Heidrun-Mistral-7B-base (few-shot),7242,32,32768,3823,2.37,2.35,2.79,1.98,40.14,39.38,21.85,58.07,50.1,54.81,48.64,10.31,1.11,42.2,48.43,79.43,17.37,57.05
ThatsGroes/munin-SkoleGPTOpenOrca-7b-16bit (few-shot),7242,32,32768,3006,2.37,2.3,2.78,2.04,45.37,39.63,21.77,58.28,51.99,52.74,50.39,0.99,1.27,47.95,44.64,77.98,16.57,57.31
microsoft/infoxlm-base,278,250,512,14918,2.37,2.41,2.45,2.24,69.78,46.78,11.27,28.28,90.14,84.12,44.42,11.2,7.12,47.69,79.43,71.48,7.26,33.72
"KennethEnevoldsen/munin_mistral-7b (few-shot, val)",7242,32,32768,2543,2.38,2.37,2.68,2.09,37.32,47.52,8.04,60.05,42.79,51.47,56.37,6.04,-0.02,48.85,45.99,77.66,6.0,60.16
bineric/NorskGPT-Mistral-7b (few-shot),7242,32,32768,2443,2.38,2.52,2.47,2.14,50.76,40.41,0.0,57.24,63.28,61.25,56.9,13.86,10.17,49.06,58.4,74.3,0.0,59.13
alexandrainst/munin-7b-8192-exp1 (few-shot),7242,32,8192,6117,2.39,2.48,2.67,2.01,30.56,36.47,26.76,58.75,50.63,54.35,39.21,20.51,11.66,51.57,47.34,73.05,30.29,57.39
KBLab/megatron-bert-base-swedish-cased-125k,135,64,512,15763,2.41,2.74,2.94,1.54,53.93,36.31,23.46,27.85,77.98,75.0,33.88,24.23,18.18,20.56,79.29,75.85,70.43,37.56
timpal0l/Mistral-7B-v0.1-flashback-v2 (few-shot),7242,32,32768,2505,2.41,2.34,2.92,1.98,41.66,47.52,17.36,51.28,48.28,50.51,49.76,14.54,9.16,32.04,44.16,80.29,34.8,51.82
clips/mfaq,278,250,128,5591,2.44,2.47,2.59,2.27,68.49,45.6,28.26,14.34,89.46,79.71,52.91,27.55,15.2,12.36,76.31,73.32,32.29,16.12
mhenrichsen/hestenettetLM (few-shot),7242,32,32768,5160,2.44,2.48,2.71,2.12,37.95,42.61,8.65,59.62,49.2,54.03,48.23,8.53,6.65,46.89,47.03,79.7,4.32,59.03
jhu-clsp/bernice,278,250,512,5567,2.46,2.44,2.77,2.18,61.98,47.2,40.52,13.53,84.11,77.82,39.63,45.75,33.74,5.35,71.34,70.91,53.52,16.41
"birgermoell/NeuralBeagle-Flashback (few-shot, val)",7242,32,32768,2904,2.48,2.17,2.68,2.58,48.28,44.2,22.79,58.16,51.78,61.22,53.06,10.27,8.06,41.18,51.73,36.06,19.42,59.03
flax-community/nordic-roberta-wiki,125,50,512,16227,2.48,2.45,2.92,2.07,60.82,34.45,41.89,26.83,85.42,78.92,36.27,48.07,29.81,0.44,72.9,61.11,55.05,29.04
DDSC/roberta-base-scandinavian,125,50,512,14491,2.49,2.55,2.71,2.21,43.9,44.48,30.37,28.89,71.73,79.8,46.74,8.02,17.04,29.26,58.84,72.28,37.61,30.59
KBLab/bert-base-swedish-cased-new,135,64,512,15933,2.49,2.87,3.0,1.59,59.37,38.46,4.61,23.13,83.23,79.16,33.94,9.56,4.16,22.84,79.99,76.04,73.52,30.6
RuterNorway/Llama-2-13b-chat-norwegian (few-shot),-1,32,4096,7778,2.49,2.37,2.93,2.16,43.17,43.4,11.08,56.81,58.61,60.4,41.36,6.52,3.95,38.93,50.85,74.17,7.51,57.32
sentence-transformers/paraphrase-xlm-r-multilingual-v1,278,250,512,14994,2.49,2.37,2.83,2.28,61.17,46.39,38.61,19.9,81.26,74.05,49.93,38.26,25.17,0.0,70.22,71.33,39.6,18.65
mistralai/Mistral-7B-Instruct-v0.2 (few-shot),7242,32,32768,2538,2.5,2.29,2.89,2.31,44.89,48.09,19.06,51.56,53.42,54.34,38.79,17.06,11.0,35.74,47.92,62.9,19.95,52.51
sentence-transformers/paraphrase-multilingual-mpnet-base-v2,278,250,512,15100,2.5,2.41,2.78,2.31,61.18,49.13,29.66,19.99,81.94,75.56,55.53,36.01,14.99,0.0,65.14,73.47,36.62,18.65
neph1/bellman-7b-mistral-instruct-v0.2 (few-shot),7242,32,32768,2518,2.52,2.27,2.98,2.32,46.11,47.58,18.41,52.78,57.01,56.77,38.81,14.16,9.29,32.75,54.38,55.84,16.05,53.22
flax-community/swe-roberta-wiki-oscar,125,50,512,15437,2.55,2.76,3.15,1.75,55.98,36.66,22.69,24.81,79.25,75.39,36.56,22.02,19.72,0.78,75.4,76.22,65.73,29.34
mistralai/Mistral-7B-v0.1 (few-shot),7242,32,32768,2657,2.56,2.48,2.99,2.21,45.42,43.16,8.79,48.51,52.0,55.12,47.25,8.66,6.8,29.44,53.34,80.0,4.61,48.43
sentence-transformers/stsb-xlm-r-multilingual,278,250,512,15040,2.56,2.54,2.89,2.24,58.52,42.26,34.8,19.6,80.08,74.59,52.16,36.3,14.21,0.0,68.94,72.77,40.21,20.09
distilbert/distilbert-base-multilingual-cased,135,120,512,26355,2.58,2.62,2.82,2.31,58.12,32.53,35.53,28.19,83.62,80.69,33.16,36.1,30.1,19.26,70.08,59.66,33.71,31.48
occiglot/occiglot-7b-eu5-instruct (few-shot),7242,32,32768,2088,2.58,2.6,2.88,2.27,34.73,42.31,1.14,57.89,45.46,52.56,44.46,0.0,0.0,52.19,41.36,71.73,7.9,57.78
mistralai/Mistral-7B-Instruct-v0.1 (few-shot),7242,32,32768,5443,2.59,2.52,2.95,2.3,37.93,44.49,14.09,51.38,50.08,51.27,43.65,14.09,8.28,37.23,45.01,73.33,11.59,52.12
Geotrend/distilbert-base-25lang-cased,109,85,512,26099,2.6,2.62,2.83,2.36,58.44,31.81,34.13,27.6,83.59,80.29,33.19,32.6,24.97,19.93,70.56,60.69,30.83,31.41
bineric/NorskGPT-Llama-7B-v0.1 (few-shot),6738,32,4096,5384,2.6,2.56,2.76,2.47,35.33,47.73,0.0,54.25,50.41,57.07,50.94,8.19,5.55,41.35,49.16,60.91,0.32,55.28
occiglot/occiglot-7b-eu5 (few-shot),7242,32,32768,2219,2.6,2.63,2.94,2.23,31.31,44.62,0.28,58.05,44.35,52.82,44.95,0.0,0.0,43.88,42.27,76.56,2.18,58.98
Geotrend/distilbert-base-en-fr-de-no-da-cased,76,42,512,26081,2.61,2.62,2.84,2.36,58.78,31.3,34.92,27.86,83.49,80.23,32.66,33.65,29.07,19.29,69.94,59.83,29.82,31.13
Geotrend/distilbert-base-en-no-cased,69,33,512,26597,2.61,2.64,2.83,2.36,57.53,32.95,33.63,27.21,83.93,79.39,32.32,36.15,30.17,19.71,69.28,59.53,29.36,30.42
Geotrend/distilbert-base-en-da-cased,69,33,512,26196,2.62,2.6,2.91,2.36,59.5,31.89,36.0,28.41,83.27,79.59,29.37,31.5,24.06,18.62,69.62,59.42,29.01,31.82
Twitter/twhin-bert-large,561,250,512,5299,2.63,2.58,3.07,2.25,66.39,39.36,7.06,33.88,86.26,80.1,34.17,12.11,4.28,11.74,74.26,63.35,16.07,36.77
Geotrend/distilbert-base-da-cased,61,23,512,28950,2.64,2.62,2.91,2.38,58.36,32.13,34.75,27.5,82.84,78.83,30.7,34.24,27.2,16.44,69.25,58.47,29.8,30.61
timpal0l/njord-alpha (few-shot),7242,32,32768,5446,2.64,2.48,3.24,2.19,21.64,52.25,14.78,55.61,39.0,44.92,52.27,16.13,10.37,5.02,31.57,79.5,16.82,54.54
danish-foundation-models/munin-7b-alpha (few-shot),7242,32,32768,6116,2.65,2.47,3.31,2.16,31.6,36.89,26.41,57.81,37.1,39.67,20.54,4.39,1.2,47.16,35.97,78.8,15.47,56.75
"merge-crew/da-sv-dare-ties-density-0.3 (few-shot, val)",7242,32,32768,2461,2.66,2.53,3.1,2.34,30.16,48.49,5.52,52.44,35.98,47.39,38.98,11.54,5.2,37.54,32.37,75.33,12.73,53.05
sarnikowski/convbert-medium-small-da-cased,24,29,512,13821,2.66,2.2,3.01,2.77,64.28,36.85,63.55,24.52,79.5,73.03,32.4,41.65,25.53,5.41,58.01,57.67,13.4,24.92
meta-llama/Llama-2-7b-chat-hf (few-shot),6738,32,4096,2643,2.69,2.47,3.13,2.47,35.44,44.88,9.74,55.04,44.99,49.09,41.56,3.04,4.03,33.77,39.72,66.18,6.74,54.07
tollefj/nordavind-7b-instruct-warm (few-shot),7248,33,2048,6450,2.69,2.61,3.11,2.35,27.66,49.44,7.5,51.24,35.16,43.9,38.05,8.45,7.5,40.47,40.15,77.91,5.55,51.41
Addedk/kbbert-distilled-cased,82,50,512,29698,2.71,2.96,3.29,1.88,57.84,31.18,13.25,22.73,81.82,75.89,33.42,14.99,13.63,0.0,80.12,71.28,51.58,28.16
danish-foundation-models/encoder-medium-v1,111,32,512,16130,2.71,2.23,2.97,2.94,63.42,39.91,51.01,25.76,68.66,61.77,36.56,31.23,5.4,22.56,49.62,58.7,2.23,25.45
sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2,118,250,512,17428,2.71,2.64,3.03,2.46,56.75,44.48,26.74,17.89,78.31,72.13,47.53,26.92,14.63,0.0,66.5,72.19,28.75,15.91
timpal0l/Mistral-7B-v0.1-flashback-v2-instruct (few-shot),7242,32,32768,5172,2.71,2.62,3.45,2.07,36.46,40.65,7.48,52.71,52.52,54.28,32.19,-0.22,0.0,20.57,51.72,77.06,14.0,56.74
jannikskytt/MeDa-Bert,111,32,511,16114,2.73,2.24,2.91,3.03,64.64,44.62,47.47,23.14,71.69,60.0,38.94,30.32,7.99,24.02,48.32,53.98,3.33,23.15
AI-Sweden-Models/gpt-sw3-20b (few-shot),20918,64,2048,4880,2.76,2.89,3.08,2.31,27.41,30.24,11.34,52.8,30.82,39.56,34.51,15.17,12.46,42.81,31.86,78.88,12.26,53.58
norallm/normistral-7b-warm (few-shot),7248,33,2048,3175,2.78,2.71,3.3,2.33,37.8,40.51,3.35,49.08,42.29,46.29,27.05,1.63,2.57,39.18,48.78,76.09,2.53,48.93
DDSC/roberta-base-danish,125,50,512,15004,2.79,2.52,3.18,2.67,63.84,43.9,17.16,26.94,76.14,72.88,32.29,0.45,-0.08,23.91,65.95,64.02,0.8,28.46
Maltehb/danish-bert-botxo,111,32,512,16091,2.79,2.19,3.23,2.96,66.71,43.79,45.96,26.29,72.62,58.73,40.65,29.47,12.95,0.91,50.29,57.42,4.94,24.16
ltg/norbert3-xs,15,50,508,14208,2.79,2.84,2.74,2.78,59.94,39.16,2.16,24.69,87.63,80.19,49.92,7.93,5.06,22.46,67.53,59.27,2.83,24.11
birgermoell/roberta-swedish-scandi,125,50,512,15385,2.81,2.95,3.44,2.04,49.22,33.51,12.08,24.49,72.74,69.74,29.68,15.83,8.7,1.04,68.55,69.96,52.88,27.99
Addedk/mbert-swedish-distilled-cased,135,120,512,26091,2.84,2.93,3.15,2.45,56.36,31.16,21.08,19.63,82.98,76.65,30.38,21.99,19.06,9.47,73.41,62.1,34.86,18.1
sarnikowski/electra-small-discriminator-da-256-cased,13,29,512,20340,2.85,2.49,3.2,2.86,60.63,24.38,68.58,21.03,73.15,66.34,29.97,40.79,25.08,1.93,52.79,57.93,14.72,20.54
meta-llama/Llama-2-7b-hf (few-shot),6738,32,4096,2648,2.86,2.8,3.43,2.36,31.77,43.91,0.31,45.42,42.13,43.8,41.74,0.0,0.02,18.67,44.11,79.05,7.34,43.42
sarnikowski/convbert-small-da-cased,13,29,512,14273,2.86,2.52,3.15,2.92,60.59,29.52,57.1,20.16,76.07,70.94,32.49,35.43,21.11,1.84,55.06,53.7,12.38,22.53
Qwen/Qwen1.5-4B-Chat (few-shot),3950,152,32768,4347,2.87,2.68,3.3,2.62,23.09,42.04,8.65,53.69,35.51,31.05,32.7,3.57,1.61,42.55,31.82,64.08,5.43,53.21
01-ai/Yi-6B (few-shot),6061,64,4096,2786,2.89,3.34,3.1,2.24,35.08,4.0,3.68,55.0,43.44,46.33,38.96,0.75,1.04,40.33,46.69,75.39,2.91,55.05
dbmdz/bert-base-historic-multilingual-cased,111,32,512,15165,2.96,3.21,3.31,2.36,47.61,24.17,8.14,25.19,68.63,67.7,25.68,6.73,3.35,22.57,68.83,64.25,28.62,28.78
sentence-transformers/distilbert-multilingual-nli-stsb-quora-ranking,135,120,512,26151,2.97,3.04,3.22,2.65,54.48,36.6,8.84,15.42,77.81,72.22,44.59,8.98,5.72,0.0,65.5,68.33,14.81,16.11
sentence-transformers/quora-distilbert-multilingual,135,120,512,26458,2.97,3.04,3.22,2.65,54.48,36.6,8.84,13.97,77.81,72.22,44.59,8.98,5.72,0.0,65.5,68.36,14.81,16.11
Maltehb/aelaectra-danish-electra-small-cased,14,32,128,6035,3.01,2.62,3.3,3.11,63.31,32.72,67.74,0.0,71.85,67.14,29.0,33.57,21.79,0.03,57.82,55.68,19.26,0.0
dbmdz/bert-medium-historic-multilingual-cased,42,32,512,24291,3.04,3.19,3.41,2.51,49.88,27.93,5.42,22.93,69.65,66.78,26.33,6.62,5.16,15.75,66.11,59.66,26.28,24.36
google/gemma-2b (few-shot),2506,256,8192,6087,3.05,2.98,3.61,2.56,15.78,40.21,2.27,50.55,15.15,20.75,32.89,1.18,0.0,33.33,21.44,75.45,3.82,51.73
Maltehb/aelaectra-danish-electra-small-uncased,14,32,128,5995,3.09,2.61,3.41,3.26,62.52,34.45,65.15,2.51,59.76,51.44,33.41,32.87,20.09,0.0,39.17,57.71,17.1,0.11
jjzha/dajobbert-base-uncased,110,32,512,16243,3.09,2.59,3.46,3.21,60.78,39.65,37.67,15.41,65.95,55.29,33.31,20.34,8.07,0.0,42.99,55.49,4.69,14.22
Qwen/Qwen1.5-4B (few-shot),3950,152,32768,3248,3.1,2.76,3.16,3.37,23.59,39.62,5.38,54.16,40.36,39.42,36.97,5.27,1.4,40.0,33.69,5.2,1.85,54.15
AI-Sweden-Models/gpt-sw3-1.3b-instruct (few-shot),1445,64,2048,4544,3.16,3.3,3.43,2.74,14.33,27.14,2.65,46.38,25.37,27.4,35.58,0.82,1.43,36.06,15.01,73.34,2.9,47.45
AI-Sweden-Models/gpt-sw3-6.7b-v2 (few-shot),7111,64,2048,2351,3.17,3.41,3.47,2.62,20.84,18.07,10.54,39.18,29.62,32.3,34.67,8.37,7.76,24.67,28.73,77.47,8.78,35.78
AI-Sweden-Models/gpt-sw3-6.7b-v2-instruct (few-shot),7111,64,2048,2383,3.27,3.61,3.31,2.88,15.35,2.85,10.99,50.51,24.67,29.03,34.39,2.42,5.11,42.52,14.58,56.6,10.92,50.18
AI-Sweden-Models/gpt-sw3-1.3b (few-shot),1445,64,2048,4608,3.28,3.32,3.65,2.87,8.8,28.65,2.84,45.31,13.49,14.74,27.28,3.09,1.86,34.9,6.08,71.38,1.17,45.53
AI-Sweden-Models/gpt-sw3-6.7b (few-shot),7111,64,2048,2285,3.29,3.26,3.66,2.95,18.23,22.71,5.03,49.11,22.35,21.98,18.23,1.68,2.49,41.8,18.83,53.68,3.49,49.81
google/gemma-2b-it (few-shot),2506,256,8192,6471,3.31,3.15,3.61,3.18,19.5,34.03,2.25,42.12,34.05,37.72,22.01,2.76,1.45,32.42,29.2,43.97,0.53,39.39
norallm/normistral-7b-scratch (few-shot),7248,33,2048,3192,3.31,3.26,3.74,2.92,14.88,34.66,0.29,42.16,14.58,21.06,32.02,1.49,0.98,22.87,13.79,71.59,-0.89,38.33
mhenrichsen/danskgpt-tiny-chat (few-shot),1100,32,2048,1745,3.35,3.18,3.74,3.13,22.31,34.05,0.7,41.82,28.74,30.34,27.49,-2.17,0.26,19.1,27.31,45.94,-0.97,35.57
sentence-transformers/distiluse-base-multilingual-cased-v1,135,120,512,26344,3.38,3.39,3.72,3.02,46.78,27.78,3.04,15.52,60.76,59.62,25.98,2.65,3.47,0.2,49.86,60.06,3.18,16.08
KBLab/albert-base-swedish-cased-alpha,14,50,512,15925,3.41,3.63,3.76,2.83,29.9,19.79,6.15,15.96,66.97,63.9,18.85,5.83,4.02,0.0,47.19,56.57,20.92,23.86
NbAiLab/nb-gpt-j-6B-alpaca (few-shot),6055,50,1024,2607,3.41,3.41,3.71,3.1,12.95,27.68,1.65,38.6,23.82,26.04,32.6,0.34,2.26,21.33,13.28,60.17,1.52,37.23
AI-Sweden-Models/gpt-sw3-356m-instruct (few-shot),471,64,2048,5855,3.43,3.32,3.72,3.25,10.37,34.94,2.08,36.59,18.57,21.17,30.88,-0.3,0.45,23.99,11.61,59.0,0.06,34.37
dbmdz/bert-mini-historic-multilingual-cased,12,32,512,47122,3.43,3.5,3.68,3.11,41.7,26.03,2.19,13.82,61.55,59.9,24.59,3.45,2.72,3.99,50.07,56.1,5.05,14.49
Qwen/Qwen1.5-1.8B (few-shot),1837,152,32768,5666,3.44,3.29,3.97,3.06,12.23,29.03,0.56,46.43,19.34,18.77,22.82,2.7,2.21,16.31,22.16,51.91,1.49,44.83
Qwen/Qwen1.5-1.8B-Chat (few-shot),1837,152,32768,8304,3.45,3.35,3.96,3.04,19.16,26.58,0.63,41.68,28.21,31.26,19.85,1.96,-0.01,16.36,24.17,52.54,0.34,43.49
HPLT/gpt-7b-nordic-prerelease (few-shot),7550,131,4096,5404,3.47,3.26,4.07,3.08,2.77,37.77,1.26,46.03,2.93,2.73,17.44,3.2,2.61,21.5,3.75,61.96,2.65,46.16
AI-Sweden-Models/gpt-sw3-356m (few-shot),471,64,2048,5758,3.5,3.44,3.65,3.42,16.13,27.61,1.96,34.81,27.37,31.22,34.21,0.92,1.25,18.54,23.77,34.29,1.57,33.71
jannesg/bertsson,124,50,512,15314,3.53,3.64,3.92,3.02,32.63,24.11,2.91,15.37,49.3,46.11,23.21,2.26,-0.66,0.68,51.13,61.67,2.87,17.24
alexanderfalk/danbert-small-cased,83,52,512,30013,3.72,3.58,3.9,3.67,33.05,30.67,13.01,1.56,42.18,37.39,24.39,7.29,2.57,0.0,22.47,53.88,1.55,1.12
3ebdola/Dialectal-Arabic-XLM-R-Base,278,250,512,15177,3.74,3.76,3.97,3.49,36.51,22.07,1.63,3.09,55.55,53.53,12.69,2.79,1.66,0.0,42.78,44.95,1.43,8.71
RuterNorway/Llama-2-7b-chat-norwegian (few-shot),-1,32,4096,10890,3.78,3.98,4.02,3.35,10.12,10.65,-0.66,26.21,21.04,18.71,12.22,-1.18,0.36,26.79,22.38,31.11,0.09,44.37
mhenrichsen/danskgpt-tiny (few-shot),1100,32,2048,8597,3.86,3.79,4.16,3.63,14.13,26.31,-0.54,14.16,27.37,27.59,18.09,-0.19,-0.8,2.15,23.92,31.93,0.46,21.56
Qwen/Qwen1.5-0.5B-Chat (few-shot),620,152,32768,11740,3.87,3.86,4.29,3.46,10.09,10.72,1.32,34.52,19.03,18.41,11.49,0.29,-0.12,7.73,13.38,40.23,0.21,29.46
allenai/OLMo-1B (few-shot),1177,50,2051,8536,3.93,3.89,4.34,3.56,9.68,17.94,-2.02,23.65,25.84,26.26,9.95,-0.95,-0.04,0.0,24.12,38.95,-1.35,17.85
Qwen/Qwen1.5-0.5B (few-shot),620,152,32768,11371,3.94,3.79,4.3,3.72,15.8,8.88,0.66,32.78,27.65,26.1,6.31,-1.59,0.61,5.95,17.46,26.58,-1.88,34.59
RabotaRu/HRBert-mini,80,200,512,54951,3.97,4.05,4.22,3.63,22.21,20.33,0.9,2.73,31.87,32.47,15.07,1.26,0.49,0.0,24.61,52.31,1.32,2.86
fresh-xlm-roberta-base,278,250,512,1319,4.08,4.14,4.26,3.83,16.04,17.37,1.34,1.58,25.49,25.94,12.6,0.5,1.83,0.0,11.91,51.11,0.86,2.0
fresh-electra-small,14,31,512,7219,4.11,4.21,4.31,3.81,12.87,18.61,0.3,0.0,18.38,12.76,15.29,0.17,0.37,0.0,10.54,55.54,-0.15,0.02
NbAiLab/nb-gpt-j-6B-v2 (few-shot),6051,50,1024,2556,4.12,4.08,4.31,3.98,0.24,27.8,0.56,6.82,5.29,6.77,20.84,0.45,0.48,2.45,0.31,27.42,0.07,17.79
AI-Sweden-Models/gpt-sw3-126m-instruct (few-shot),186,64,2048,7717,4.15,4.13,4.27,4.04,13.98,6.37,0.41,20.46,27.66,30.88,5.13,0.0,0.0,7.55,23.05,12.47,0.08,20.43
NbAiLab/nb-gpt-j-6B@sharded (few-shot),-1,50,1024,2630,4.32,4.39,4.43,4.13,0.36,11.0,-0.11,5.16,0.22,0.24,20.64,-0.99,-0.15,0.55,0.01,33.5,-0.02,4.82
AI-Sweden-Models/gpt-sw3-126m (few-shot),186,64,2048,8958,4.45,4.36,4.56,4.44,3.43,9.18,-0.22,7.7,13.55,9.38,7.78,-1.46,-2.97,0.9,5.66,8.15,-0.81,7.64
RJuro/kanelsnegl-v0.1 (few-shot),7242,32,512,9757,4.52,4.51,4.79,4.26,0.0,13.0,0.0,0.0,0.0,0.0,0.95,0.0,0.0,0.0,0.0,34.63,0.0,0.0
RJuro/kanelsnegl-v0.2 (few-shot),7242,32,512,1373,4.56,4.64,4.79,4.26,0.0,4.81,0.0,0.0,0.0,0.0,1.27,0.0,0.0,0.0,0.0,28.62,0.0,0.0
ai-forever/mGPT (few-shot),-1,100,1024,13551,4.67,4.66,4.67,4.68,0.65,2.61,-0.73,2.0,0.08,0.0,4.76,0.67,-0.88,0.0,0.0,0.0,0.49,6.24
peter-sk/gpt-neox-da (few-shot),1515,50,1024,6025,4.77,4.76,4.82,4.72,0.64,-0.52,-0.02,0.48,0.29,0.25,-1.43,-0.42,1.11,0.0,0.26,4.75,-0.6,0.06
